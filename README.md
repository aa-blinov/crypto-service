# Криптовалютный сервис

## Описание путей

* `/api/prices` - получить цену по всем монетам, которые представлены сразу на двух криптовалютных биржах - **Binance**
  и **ByBit**. Формат: `[{"name": "BTC", "prices": {"binance": 71000, "bybit": 71000 }},
  {"name": "ETH", "prices": {"binance": 4000, "bybit": 4000 }}, ...`.
* `api/prices/{coin_name}` - получить данные по конкретной монете, если информации по цене нет, то в поле цены
  вернется `null`. Формат: `{"name": "COIN_NAME(example BTC)", "prices": {"binance": 71000, "bybit": 71000}}`.

## Сборка и запуск

Решение не опубликовано на `DockerHub`, поэтому предстоит вручную произвести сборку и запуск решения.

* `docker compose build api` - локальная сборка;
* `docker compose up api` - локальный запуск в интерактивном режиме по пути: http://localhost:8001.

## Уточнения ТЗ

* При массовом получении цен монет (`/api/prices`), считаем, что если хотя бы один сервис недоступен или не отвечает по
  ожидаемому таймауту, то пользователь получает ответ: `503 - Не удалось получить цены от всех криптовалютных бирж.
  Попробуйте позже.`
* При точечном получения цены монеты (`api/prices/{coin_name}`) считаем, что если указанная монета не представлена
  на обеих площадках, то это временно, то есть пользователь запрашивает всегда монету, которая может быть представлена.
* Для определения цены монеты в рамках записей API `Binance` используется аттрибут `price`,
  а в рамках `ByBit` - `last_price`. В двух случаях значения определяют последнюю цену.
* Исходя их формата возвращаемых значений, приведенных в ТЗ, можно сделать вывод, что цена монеты всегда
  округлена до целого. Будем пользоваться банковским округлением - функция стандартной библиотеки `round()`.
* API бирж определяет "пару" и возвращает по ним цену, например, по `BTC` не будет найдено результатов, но по `BTCUSDT`
  будут.

## Точки роста сервиса

* Написать unit-тесты по обработке данных бирж на нашей стороне и интеграционные для проверки корректности
  взаимодействия с биржами.
* Выделение масштабируемой структуры проекта: https://fastapi.tiangolo.com/tutorial/bigger-applications/.
* Переход от стандартных типов к моделям `Pydantic` для валидации входных и выходных сущностей сервиса.
  Дополнительно это добавит возможность пользователю в `Swagger` видеть схемы для понимания, какие запросы ему
  необходимо
  построить при отправке и что ему придет в ответ.
* Вынести получение и разбор данных с бирж в фоновый процесс (отельный `Python`-интерпретатор) для избегания блокировок,
  которые будут из-за CPU-интенсивной обработки данных внешних источников(awaitable участок сейчас крайне мал по
  длительности, поэтому это будет ощутимо). Временно блокировки можно избежать через механизмы
  репликации сервисов. Считается плохой практикой, когда сервис выступает в роли прокси для сервиса третьей стороны,
  так как в момент запроса могут возникнуть различные проблемы, начиная от несоответствия схем данных,
  заканчивая внутренними ошибками стороннего сервиса, и следовательно, простоем нашего сервиса.
  Хорошей практикой будет производить фоново получение и разбор данных и хранить отображения этих данных в своей БД.
  В этому случае мы всегда можем отдать пользователю валидные данные, но возможна некоторая задержка по актуализации
  этих данных, которая регулируется настройкой регулярности задачи сбора и обработки данных планировщиком.
  Дополнительно, так как пользователь не будет ожидать интенсивную обработку данных перед их получением,
  то время реагирования API на запросы сократится.
* Хранить перечень валидных монет для запроса цен по ним, так как пользователь, может вводить намеренно
  некорректную информацию.
* Добавить авторизацию для методов API, чтобы им пользовались только доверенные лица в рамках договоренностей
  (оплата и т.п.).
* Добавить ограничитель числа запросов в разрезе путей API в рамках сессий пользователей, чтобы сервис всегда получал
  контролируемую нагрузку.
* Подключить сервис для отслеживания ошибок, производительности и профилирования, например, Sentry.
* Разбить docker-образы на два. Первый инкапсулирует зависимости, а второй - код, так как зависимости изменяются сильно
  реже кода.
* Для контроля разработки использовать для проекта связку из следующих утилит с согласованными командой
  конфигурациями - `black`, `flake8`, `mypy`, `bandit`. Запуск тестов должен быть включен как и указанные утилиты
  в процесс создания PR/MR, например, через `Github Actions`или локально.
* Перенести хранение конфигураций сервиса в защищенную среду вместо .env-файла.